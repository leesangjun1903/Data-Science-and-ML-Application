# Machine Learning Theory
## Python Machine Learning for Beginners, 
Chapter 1: Introduction and Environment Set Up  
Chapter 2: Python Crash Course  
Chapter 3: Python NumPy Library for Data Analysis  
Chapter 4: Introduction to Pandas Library for Data Analysis  
Chapter 5: Data Visualization via Matplotlib, Seaborn, and Pandas Libraries  
Chapter 6: Solving Regression Problems in Machine Learning Using Sklearn Library  
Chapter 7: Solving Classification Problems in Machine Learning Using Sklearn Library  
Chapter 8: Data Clustering with Machine Learning Using Sklearn Library  
Chapter 9: Deep Learning with Python TensorFlow 2.0  
Chapter 10: Dimensionality Reduction with PCA and LDA Using Sklearn  

## Introduction to Machine Learning with Python, Andreas C. Müller
Supervised Learning  
Unsupervised Learning and Preprocessing  
Representing Data and Engineering Features  
Model Evaluation and Improvement  
Algorithm Chains and Pipelines  
Working with Text Data  
Wrapping Up  

## Deep Learning from Scratch, Seth Weidman
Foundations  
Fundamentals  
Deep Learning from Scratch  
Extensions  
Convolutional Neural Networks  
Recurrent Neural Networks  
PyTorch  

## PYTHON MACHINE LEARNING: MACHINE LEARNING AND DEEP LEARNING FROM SCRATCH ILLUSTRATED WITH PYTHON, SCIKIT-LEARN, KERAS, THEANO AND TENSORFLOW, MOUBACHIR MADANI FADOUL
Chapter 1. Python Deep Learning Tutorial  
Chapter 2. Python Deep Basic Machine Learning  
Chapter 3. Artificial Neural Networks  
Chapter 4. Training a Neural Network  
Chapter 5. Python Deep Learning - Implementations  

## Dive into Deep Learning, ASTON ZHANG
Data Manipulation  
Data Preprocessing  
Linear Algebra  
Calculus  
Automatic Differentiation  
Probability and Statistics  
Linear Regression  
Object-Oriented Design for Implementation  
Synthetic Regression Data  
Linear Regression Implementation from Scratch  
Concise Implementation of Linear Regression  
Generalization  
Weight Decay  
Softmax Regression  
The Image Classification Dataset  
The Base Classification Model  
Softmax Regression Implementation from Scratch  
Concise Implementation of Softmax Regression  
Generalization in Classification  
Environment and Distribution Shift  
Multilayer Perceptrons  
Implementation of Multilayer Perceptrons  
Forward Propagation, Backward Propagation, and Computational Graphs  
Numerical Stability and Initialization  
Generalization in Deep Learning  
Dropout  
Predicting House Prices on Kaggle  
Layers and Modules  
Parameter Management  
Parameter Initialization  
Lazy Initialization  
Custom Layers  
File I/O  
GPUs  
From Fully Connected Layers to Convolutions  
Convolutions for Images  
Padding and Stride  
Multiple Input and Multiple Output Channels  
Pooling  
Convolutional Neural Networks (LeNet)  
Deep Convolutional Neural Networks (AlexNet)  
Networks Using Blocks (VGG)  
Network in Network (NiN)  
Multi-Branch Networks (GoogLeNet)  
Batch Normalization  
Residual Networks (ResNet) and ResNeXt  
Densely Connected Networks (DenseNet)  
Designing Convolution Network Architectures  
Working with Sequences  
Converting Raw Text into Sequence Data  
Language Models  
Recurrent Neural Networks  
Recurrent Neural Network Implementation from Scratch  
Concise Implementation of Recurrent Neural Networks  
Backpropagation Through Time  
Long Short-Term Memory (LSTM)  
Gated Recurrent Units (GRU)  
Deep Recurrent Neural Networks  
Bidirectional Recurrent Neural Networks  
Machine Translation and the Dataset  
The Encoder−Decoder Architecture  
Sequence-to-Sequence Learning for Machine Translation  
Beam Search  
Queries, Keys, and Values  
Attention Pooling by Similarity  
Attention Scoring Functions  
The Bahdanau Attention Mechanism  
Multi-Head Attention  
Self-Attention and Positional Encoding  
The Transformer Architecture  
Transformers for Vision  
Large-Scale Pretraining with Transformers  
Optimization and Deep Learning  
Convexity  
Gradient Descent  
Stochastic Gradient Descent  
Minibatch Stochastic Gradient Descent  
Momentum  
Adagrad  
RMSProp  
Adadelta  
Adam  
Learning Rate Scheduling  
Compilers and Interpreters  
Asynchronous Computation  
Automatic Parallelism  
Hardware  
Training on Multiple GPUs  
Concise Implementation for Multiple GPUs  
Parameter Servers  
Image Augmentation  
Fine-Tuning  
Object Detection and Bounding Boxes  
Anchor Boxes  
Multiscale Object Detection  
The Object Detection Dataset  
Single Shot Multibox Detection  
Region-based CNNs (R-CNNs)  
Semantic Segmentation and the Dataset  
Transposed Convolution  
Fully Convolutional Networks  
Neural Style Transfer  
Image Classification (CIFAR-10) on Kaggle  
Dog Breed Identification (ImageNet Dogs) on Kaggle  
Word Embedding (word2vec)  
Approximate Training  
The Dataset for Pretraining Word Embeddings  
Pretraining word2vec  
Word Embedding with Global Vectors (GloVe)  
Subword Embedding  
Word Similarity and Analogy  
Bidirectional Encoder Representations from Transformers (BERT)  
The Dataset for Pretraining BERT  
Pretraining BERT  
Sentiment Analysis and the Dataset  
Sentiment Analysis: Using Recurrent Neural Networks  
Sentiment Analysis: Using Convolutional Neural Networks  
Natural Language Inference and the Dataset  
Natural Language Inference: Using Attention  
Fine-Tuning BERT for Sequence-Level and Token-Level Applications  
Natural Language Inference: Fine-Tuning BERT  
Markov Decision Process (MDP)  
Value Iteration  
Q-Learning  
Introduction to Gaussian Processes  
Gaussian Process Priors  
Gaussian Process Inference  
What Is Hyperparameter Optimization?  
Hyperparameter Optimization API  
Asynchronous Random Search  
Multi-Fidelity Hyperparameter Optimization  
Asynchronous Successive Halving  
Generative Adversarial Networks  
Deep Convolutional Generative Adversarial Networks  
Overview of Recommender Systems 

## Hands-On Deep Learning Algorithms with Python, Sudharsan Ravichandiran
Introduction to Deep Learning  
Getting to Know TensorFlow  
Gradient Descent and Its Variants  
Generating Song Lyrics Using RNN  
Improvements to the RNN  
Demystifying Convolutional Networks  
Learning Text Representations  
Generating Images Using GANs  
Learning More about GANs  
Reconstructing Inputs Using Autoencoders  
Exploring Few-Shot Learning Algorithms  

## UNDERSTANDING MACHINE LEARNING, Shai Shalev-Shwartz
A Gentle Start  
A Formal Learning Model  
Learning via Uniform Convergence  
The Bias-Complexity Tradeoff  
The VC-Dimension  
Nonuniform Learnability  
The Runtime of Learning  
Linear Predictors  
Boosting  
Model Selection and Validation  
Convex Learning Problems  
Regularization and Stability  
Stochastic Gradient Descent  
Support Vector Machines  
Kernel Methods  
Multiclass, Ranking, and Complex Prediction Problems  
Decision Trees  
Nearest Neighbor  
Neural Networks  
Online Learning  
Clustering  
Dimensionality Reduction  
Generative Models  
Feature Selection and Generation  
Rademacher Complexities  
Covering Numbers  
Proof of the Fundamental Theorem of Learning Theory  
Multiclass Learnability  
Compression Bounds  
PAC-Bayes  

## Neural Networks and Deep Learning, Michael Nielsen
Using neural nets to recognize handwritten digits  
How the backpropagation algorithm works  
Improving the way neural networks learn  
A visual proof that neural nets can compute any function  
Why are deep neural networks hard to train?  
Deep learning

## Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow, Aurélien Géron
1. The Machine Learning Landscape
2. End-to-End Machine Learning Project
3. Classification
4. Training Models
5. Support Vector Machines
6. Decision Trees
7. Ensemble Learning and Random Forests
8. Dimensionality Reduction
9. Unsupervised Learning Techniques
10. Introduction to Artificial Neural Networks with Keras
11. Training Deep Neural Networks
12. Custom Models and Training with TensorFlow
13. Loading and Preprocessing Data with TensorFlow
14. Deep Computer Vision Using Convolutional Neural Networks
15. Processing Sequences Using RNNs and CNNs
16. Natural Language Processing with RNNs and Attention
17. Representation Learning and Generative Learning Using Autoencoders and GANs
18. Reinforcement Learning
19. Training and Deploying TensorFlow Models at Scale

## Deep Learning in Python, LazyProgrammer
Chapter 1: What is a neural network?  
Chapter 2: Biological analogies  
Chapter 3: Getting output from a neural network  
Chapter 4: Training a neural network with backpropagation  
Chapter 5: Theano  
Chapter 6: TensorFlow  
Chapter 7: Improving backpropagation with modern techniques - momentum, adaptive learning rate, and regularization  
Chapter 8: Unsupervised learning, autoencoders, restricted Boltzmann machines, convolutional neural networks, and LSTMs  
Chapter 9: You know more than you think you know

# Statistics with Machine Learning
## Statistics and Machine Learning in Python, Edouard Duchesnay
Python language  
Scientific Python  
Statistics  
Machine Learning  
Deep Learning  

## Practical Statistics for Data Scientists, Peter Bruce
Exploratory Data Analysis  
Data and Sampling Distributions  
Statistical Experiments and Significance Testing  
Regression and Prediction  
Classification  
Statistical Machine Learning  
Unsupervised Learning  


## Deep Learning with PyTorch, ELI STEVENS
Introducing deep learning and the PyTorch Library  
Pretrained networks  
It starts with a tensor  
Real-world data representation using tensors  
The mechanics of learning  
Using a neural network to fit the data  
Telling birds from airplanes: Learning from images  
Using convolutions to generalize  
Using PyTorch to fight cancer  
Combining data sources into a unified dataset  
Training a classification model to detect suspected tumors  
Improving training with metrics and augmentation  
Using segmentation to find suspected nodules  
End-to-end nodule analysis, and where to go next  
Deploying to production  

## Deep Learning with TensorFlow and Keras, Amita Kapoor
Chapter 1: Neural Network Foundations with TF  
Chapter 2: Regression and Classification  
Chapter 3: Convolutional Neural Networks  
Chapter 4: Word Embeddings  
Chapter 5: Recurrent Neural Networks  
Chapter 6: Transformers  
Chapter 7: Unsupervised Learning  
Chapter 8: Autoencoders  
Chapter 9: Generative Models  
Chapter 10: Self-Supervised Learning  
Chapter 11: Reinforcement Learning  
Chapter 12: Probabilistic TensorFlow  
Chapter 13: An Introduction to AutoML  
Chapter 14: The Math Behind Deep Learning  
Chapter 15: Tensor Processing Unit  
Chapter 16: Other Useful Deep Learning Libraries  
Chapter 17: Graph Neural Networks  
Chapter 18: Machine Learning Best Practices  
Chapter 19: TensorFlow 2 Ecosystem  
Chapter 20: Advanced Convolutional Neural Networks  

## Deep Learning : A Practitioner’s Approach, Josh Patterson
1. A Review of Machine Learning
2. Foundations of Neural Networks and Deep Learning
3. Fundamentals of Deep Networks
4. Major Architectures of Deep Networks
5. Building Deep Networks
6. Tuning Deep Networks
7. Tuning Specific Deep Network Architectures
8. Vectorization
9. Using Deep Learning and DL4J on Spark

## Neural Networks and Deep Learning, 

## Pro Deep Learning with TensorFlow 2.0, Santanu Pattanayak
Chapter 1: Mathematical Foundations  
Chapter 2: Introduction to Deep-­ Learning Concepts and TensorFlow  
Chapter 3: Convolutional Neural Networks  
Chapter 4: Natural Language Processing  
Chapter 5: Unsupervised Learning with Restricted Boltzmann Machines and Autoencoders  
Chapter 6: Advanced Neural Networks  

## 딥러닝과 수학, 오승상
Introduction to Deep Learning  
Deep Neural Network  
Convolutional Neural Network  
Recurrent Neural Network  
Attention Mechanism  
Auto-Encoder & VAE  
Generative Adversarial Network  
Natural Language Processing  
Graph Neural Network  

## 모두의 딥러닝, 조태호


## Automated Machine Learning, Frank Hutter
Automated machine learning, also referred to as automated ML or AutoML, is the process of automating the time-consuming, iterative tasks of machine learning model development.  

- Hyperparameter Optimization
- Meta-Learning
- Neural Architecture Search
- Auto-WEKA: Automatic Model Selection and Hyperparameter Optimization in WEKA
- Hyperopt-Sklearn
- Auto-sklearn: Efficient and Robust Automated Machine Learning
- Towards Automatically-Tuned Deep Neural Networks
- TPOT: A Tree-Based Pipeline Optimization Tool for Automating Machine Learning
- The Automatic Statistician
- Analysis of the AutoML Challenge Series 2015–2018 

## Artificial Intelligence By Example, Denis Rothman
Chapter 1: Getting Started with Next-Generation Artificial Intelligence through Reinforcement Learning  
Chapter 2: Building a Reward Matrix – Designing Your Datasets  
Chapter 3: Machine Intelligence – Evaluation Functions and Numerical Convergence  
Chapter 4: Optimizing Your Solutions with K-Means Clustering  
Chapter 5: How to Use Decision Trees to Enhance K-Means Clustering  
Chapter 6: Innovating AI with Google Translate  
Chapter 7: Optimizing Blockchains with Naive Bayes  
Chapter 8: Solving the XOR Problem with a Feedforward Neural Network  
Chapter 9: Abstract Image Classification with Convolutional Neural Networks (CNNs)  
Chapter 10: Conceptual Representation Learning  
Chapter 11: Combining Reinforcement Learning and Deep Learning  
Chapter 12: AI and the Internet of Things (IoT)  
Chapter 13: Visualizing Networks with TensorFlow 2.x and TensorBoard  
Chapter 14: Preparing the Input of Chatbots with Restricted Boltzmann Machines (RBMs) and Principal Component Analysis (PCA)  
Chapter 15: Setting Up a Cognitive NLP UI/CUI Chatbot  
Chapter 16: Improving the Emotional Intelligence Deficiencies of Chatbots  
Chapter 17: Genetic Algorithms in Hybrid Neural Networks  
Chapter 18: Neuromorphic Computing  
Chapter 19: Quantum Computing  

## Approaching (Almost) Any Machine Learning Problem, ABHISHEK THAKUR
Setting up your working environment  
Supervised vs unsupervised learning  
Cross-validation  
Evaluation metrics  
Arranging machine learning projects  
Approaching categorical variables  
Feature engineering  
Feature selection  
Hyperparameter optimization  
Approaching image classification & segmentation  
Approaching text classification/regression  
Approaching ensembling and stacking  
Approaching reproducible code & model serving  

## Fundamentals of Deep Learning, Nikhil Buduma
Fundamentals of Linear Algebra for Deep Learning  
Fundamentals of Probability  
The Neural Network  
Training Feed-Forward Neural Networks  
Implementing Neural Networks in PyTorch  
Beyond Gradient Descent  
Convolutional Neural Networks  
Embedding and Representation Learning  
Models for Sequence Analysis  
Generative Models  
Methods in Interpretability  
Memory Augmented Neural Networks  
Deep Reinforcement Learning

## cs231n, Fei-Fei Li
Image Classification pipeline  
Loss functions and Optimization  
Backpropagation and Neural Networks  
Training Neural Networks  
Convolutional Neural Networks  
Spatial Localization and Detection  
Understanding and Visualizing Convolutional Neural Networks  
Recurrent Neural Networks  
CNNs in Practice  
Software Packages: Caffe / Torch / Theano / TensorFlow  
Segmentation and Attention  
Videos, Unsupervised Learning  

# Generative AI
## Generative Deep Learning, David Foster
Generative Modeling  
Deep Learning  
Variational Autoencoders  
Generative Adversarial Networks  
Autoregressive Models  
Normalizing Flow Models  
Energy-Based Models  
Diffusion Models  
Transformers  
Advanced GANs  
Music Generation  
World Models  
Multimodal Models  
Timeline of Generative AI 

## Long Short-Term Memory Networks With Python, Jason Brownlee
What are LSTMs  
How to Train LSTMs  
How to Prepare Data for LSTMs  
How to Develop LSTMs in Keras  
Models for Sequence Prediction  
How to Develop Vanilla LSTMs  
How to Develop Stacked LSTMs  
How to Develop CNN LSTMs  
How to Develop Encoder-Decoder LSTMs  
How to Develop Bidirectional LSTMs  
How to Develop Generative LSTMs  
How to Diagnose and Tune LSTMs  
How to Make Predictions with LSTMs  
How to Update LSTM Models  

## Deep Learning for Coders with fastai and PyTorch, Jeremy Howard
Your Deep Learning Journey  
From Model to Production  
Data Ethics  
Under the Hood: Training a Digit Classifier  
Image Classification  
Other Computer Vision Problems  
Training a State-of-the-Art Model  
Collaborative Filtering Deep Dive  
Tabular Modeling Deep Dive  
NLP Deep Dive: RNNs  
Data Munging with fastai’s Mid-Level API  
A Language Model from Scratch  
Convolutional Neural Networks  
ResNets  
Application Architectures Deep Dive  
The Training Process  
A Neural Net from the Foundations  
CNN Interpretation with CAM  
A fastai Learner from Scratch  

## Machine Learning with Python Cookbook, Kyle Gallatin
Working with Vectors, Matrices, and Arrays in NumPy  
Loading Data  
Data Wrangling  
Handling Numerical Data  
Handling Categorical Data  
Handling Text  
Handling Dates and Times  
Handling Images  
Dimensionality Reduction Using Feature Extraction  
Dimensionality Reduction Using Feature Selection  
Model Evaluation  
Model Selection  
Linear Regression  
Trees and Forests  
K-Nearest Neighbors  
Logistic Regression  
Support Vector Machines  
Naive Bayes  
Clustering  
Tensors with PyTorch  
Neural Networks  
Neural Networks for Unstructured Data  
Saving, Loading, and Serving Trained Models  


## Python Deep Learning Cookbook, Indra den Bakker
Programming Environments, GPU Computing, Cloud Solutions, and Deep Learning Frameworks  
Feed-Forward Neural Networks  
Convolutional Neural Networks  
Recurrent Neural Networks  
Reinforcement Learning  
Generative Adversarial Networks  
Computer Vision  
Natural Language Processing  
Speech Recognition and Video Analysis  
Time Series and Structured Data  
Game Playing Agents and Robotics  
Hyperparameter Selection, Tuning, and Neural Network Learning  
Network Internals  
Pretrained Models  

## TensorFlow 1.x Deep Learning Cookbook, Antonio Gulli
TensorFlow - An Introduction  
Regression  
Neural Networks - Perceptron  
Convolutional Neural Networks  
Advanced Convolutional Neural Networks  
Recurrent Neural Networks  
Unsupervised Learning  
Autoencoders  
Reinforcement Learning  
Mobile Computation  
Generative Models and CapsNet  
Distributed TensorFlow and Cloud Deep Learning  
Learning to Learn with AutoML (Meta-Learning)  
TensorFlow Processing Units  

## Python Machine Learning, 
Giving Computers the Ability to Learn from Data  
Training Simple Machine Learning Algorithms for Classification  
A Tour of Machine Learning Classifiers Using scikit-learn  
Building Good Training Sets – Data Preprocessing  
Compressing Data via Dimensionality Reduction  
Learning Best Practices for Model Evaluation and Hyperparameter Tuning  
Combining Different Models for Ensemble Learning  
Applying Machine Learning to Sentiment Analysis  
Embedding a Machine Learning Model into a Web Application  
Predicting Continuous Target Variables with Regression Analysis  
Working with Unlabeled Data – Clustering Analysis  
Implementing a Multilayer Artificial Neural Network from Scratch  
Parallelizing Neural Network Training with TensorFlow  
Going Deeper – The Mechanics of TensorFlow  
Classifying Images with Deep Convolutional Neural Networks  
Modeling Sequential Data Using Recurrent Neural Networks  
Project one – performing sentiment analysis of IMDb movie reviews using multilayer RNNs  
Project two – implementing an RNN for character-level language modeling in TensorFlow

## Applied Deep Learning with TensorFlow 2: Learn to Implement Advanced Deep Learning Techniques with Python, Umberto Michelucci
Chapter 1: Optimization and Neural Networks  
Chapter 2: Hands-on with a Single Neuron  
Chapter 3: Feed-Forward Neural Networks  
Chapter 4: Regularization  
Chapter 5: Advanced Optimizers  
Chapter 6: Hyper-Parameter Tuning  
Chapter 7: Convolutional Neural Networks  
Chapter 8: A Brief Introduction to Recurrent Neural Networks  
Chapter 9: Autoencoders  
Chapter 10: Metric Analysis  
Chapter 11: Generative Adversarial Networks (GANs)    

# Anomaly Detection
## Beginning Anomaly Detection Using Python-Based Deep Learning, Suman Kalyan Adari
Chapter 1: Introduction to Anomaly Detection  
Chapter 2: Introduction to Data Science  
Chapter 3: Introduction to Machine Learning  
Chapter 4: Traditional Machine Learning Algorithms  
Chapter 5: Introduction to Deep Learning  
Chapter 6: Autoencoders  
Chapter 7: Generative Adversarial Networks  
Chapter 8: Long Short-Term Memory Models  
Chapter 9: Temporal Convolutional Networks  
Chapter 10: Transformers  
Chapter 11: Practical Use Cases and Future Trends of Anomaly Detection  


# ETC
Reproducing Kernel Hilbert Space, Mercer’s Theorem, Eigenfunctions, Nystr¨ om Method, and Use of Kernels in Machine Learning: Tutorial and Survey, Benyamin Ghojogh  
An Introduction to Reproducing Kernel Hilbert Spaces and Why They are So Useful, Grace Wahba  
