# Design a machine learning system

기계 학습 시스템을 설계하는 것은 반복적인 프로세스입니다.  
프로세스에는 일반적으로 프로젝트 설정, 데이터 파이프라인, 모델링(모델 선택, 교육 및 디버깅) 및 제공(테스트, 배포, 유지 관리)의 네 가지 주요 구성 요소가 있습니다.  

사용 가능한 데이터를 조사한 후 이전에 정의한 문제를 해결하는 데 필요한 데이터를 얻는 것이 불가능하다는 것을 깨닫고 문제를 다르게 구성해야 합니다.  
학습 후 더 많은 데이터가 필요하거나 데이터에 레이블을 다시 지정해야 함을 알게 됩니다.  
초기 사용자에게 모델을 제공한 후 제품을 사용하는 방식이 모델을 교육할 때 가정한 것과 매우 다르기 때문에 모델을 업데이트해야 합니다.  

## Project setup
### Goals: 
이 문제로 무엇을 달성하고 싶습니까?  
예를 들어 Facebook의 뉴스피드에서 첫 번째로 표시할 활동의 순위를 매기는 시스템을 만들라는 요청을 받은 경우 가능한 목표 중 일부는 다음과 같습니다.  
잘못된 정보의 확산 최소화, 후원 콘텐츠의 수익 극대화 또는 사용자 최대화 ' 약혼.
### User experience:  
면접관에게 최종 사용자가 시스템을 사용하는 방법에 대한 단계별 설명을 요청하십시오.  
전화 사용자가 다음에 어떤 앱을 사용할지 예측하라는 메시지가 표시되면 예측이 언제 어떻게 사용되는지 알고 싶을 수 있습니다.  
사용자가 휴대전화를 잠금 해제할 때만 또는 휴대전화를 사용하는 동안에만 예상 검색어를 표시하나요?
### 성능 제약 조건:  
예측이 얼마나 빠르고/양호해야 합니까? 무엇이 더 중요합니까: 정밀도 또는 재현율?  
비용이 더 많이 드는 것: 위음성 또는 위양성?  
예를 들어 누군가가 특정 의료 문제에 취약한지 여부를 예측하는 시스템을 구축하는 경우 시스템에 위음성이 없어야 합니다.  
그러나 사용자가 휴대전화에서 다음에 입력할 단어를 예측하는 시스템을 구축하는 경우 사용자에게 가치를 제공하기 위해 완벽할 필요는 없습니다.
### 평가:  
교육 및 추론 중에 시스템 성능을 어떻게 평가하시겠습니까?  
추론하는 동안 시스템의 성능은 사용자의 반응에서 추론할 수 있습니다.  
시스템의 제안을 선택한 횟수. 이 지표를 미분할 수 없는 경우 훈련 중에 사용할 다른 지표가 필요합니다.  
최적화할 손실 함수. 생성 모델의 경우 평가가 매우 어려울 수 있습니다.  
예를 들어 대화 시스템을 구축하라는 요청을 받은 경우 시스템의 응답을 어떻게 평가합니까?
### Personalization:  
모델이 얼마나 개인화되어야 합니까?  
모든 사용자, 사용자 그룹 또는 각 사용자에 대해 개별적으로 하나의 모델이 필요합니까?  
여러 모델이 필요한 경우 모든 데이터에 대해 기본 모델을 교육하고 각 그룹 또는 각 사용자에 대해 미세 조정할 수 있습니까?  
프로젝트 제약 조건: 현실 세계에서 걱정해야 하지만 인터뷰 중에는 덜 걱정해야 하는 제약 사항입니다.  
배포까지 남은 시간, 사용 가능한 컴퓨팅 성능, 프로젝트, 사용할 수 있는 시스템 등

## Data pipeline
시스템의 입력 및 출력을 지정해야 합니다.  
문제의 틀을 잡는 방법에는 여러 가지가 있습니다.  
앱 예측 문제를 고려하십시오.  
순진한 설정은 사용자 프로필(나이, 성별, 민족, 직업, 소득, 기술 지식 등)과 환경 프로필(시간, 위치, 이전에 사용한 앱 등)을 입력 및 출력으로 확률 분포를 갖는 것입니다.  
사용 가능한 모든 단일 앱. 앱이 너무 많고 새 앱이 추가되면 모델을 다시 학습시켜야 하므로 이는 좋지 않은 접근 방식입니다.  
더 나은 접근 방식은 사용자 프로필, 환경 및 앱 프로필을 입력으로 사용하고 일치 여부에 관계없이 이진 분류를 출력하는 것입니다.

### 데이터 가용성 및 수집: 
어떤 종류의 데이터를 사용할 수 있습니까?  
이미 얼마나 많은 데이터가 있습니까?  
주석이 달려 있습니까? 그렇다면 주석은 얼마나 좋은 것입니까?  
데이터에 주석을 추가하는 데 비용이 얼마나 드나요?  
각 샘플에 몇 개의 주석자가 필요합니까?  
주석 작성자의 불일치를 해결하는 방법은 무엇입니까?  
그들의 데이터 예산은 얼마입니까?  
사람이 주석을 단 소량의 데이터에서 주석이 달린 새 데이터를 자동으로 생성하기 위해 약하게 감독되거나 감독되지 않는 방법을 사용할 수 있습니까?  
사용자 데이터: 사용자로부터 어떤 데이터가 필요합니까?  
어떻게 수집합니까?  
시스템에 대한 사용자의 피드백을 어떻게 받고, 그 피드백을 온라인 또는 주기적으로 시스템을 개선하는 데 사용하려면?  
### 스토리지: 
데이터는 현재 어디에 저장되어 있습니까? 클라우드, 로컬 또는 사용자 장치?  
각 샘플의 크기는 얼마입니까?  
샘플이 메모리에 맞습니까?  
데이터에 어떤 데이터 구조를 사용할 계획이며 그 장단점은 무엇입니까?  
새 데이터는 얼마나 자주 들어오나요?
### 데이터 전처리 및 표현: 
원시 데이터를 모델에 유용한 형식으로 어떻게 처리합니까?  
피처 엔지니어링 또는 피처 추출을 수행해야 합니까?  
정규화가 필요합니까?  
누락된 데이터는 어떻게 해야 합니까?  
데이터에 클래스 불균형이 있는 경우 어떻게 처리할 계획입니까?  
훈련 세트와 테스트 세트가 동일한 분포에서 오는지 여부를 평가하는 방법과 그렇지 않은 경우 어떻게 해야 합니까?  
텍스트, 숫자, 이미지 등 서로 다른 유형의 데이터가 있는 경우 이들을 어떻게 결합할 계획입니까?  
### 과제: 
사용자 데이터를 잘못 처리하여 문제를 일으킨 많은 회사에서 알 수 있듯이 사용자 데이터를 처리하려면 특별한 주의가 필요합니다.  
### 프라이버시: 
사용자는 자신의 데이터에 대해 어떤 프라이버시 문제를 가지고 있습니까?  
데이터에 어떤 익명화 방법을 사용하시겠습니까?  
사용자의 데이터를 서버에 다시 저장할 수 있습니까, 아니면 장치에서만 데이터에 액세스할 수 있습니까?
### 편향: 
데이터에서 나타낼 수 있는 편향은 무엇입니까?  
편견을 어떻게 바로잡겠습니까?  
데이터와 주석이 포괄적입니까?  
귀하의 데이터가 현재의 사회적 편견을 강화할 것입니까?

## Modeling
### Model selection

http://martin.zinkevich.org/rules_of_ml/rules_of_ml.pdf

Google의 연구 과학자인 Martin Zinkevich는 자신의 핸드북 Rules of Machine Learning: Best Practices for ML Engineering에서  
"기계 학습이 100% 부스트를 제공하고 휴리스틱을 사용하면 50%까지 도달할 수 있습니다."  
그러나 점점 더 복잡해지는 휴리스틱의 함정에 저항하십시오.  
시스템에 100개 이상의 중첩된 if-else가 있는 경우 기계 학습으로 전환해야 합니다. 

# Training
## Debugging
모델의 성능이 저하되는 데는 여러 가지 이유가 있습니다.  
- 이론적 제약 사항: 
예. 잘못된 가정, 잘못된 모델/데이터 적합성.
- 잘못된 모델 구현: 
모델에 구성 요소가 많을수록 잘못될 수 있는 일이 많아지고 무엇이 잘못되었는지 파악하기가 더 어려워집니다.
- 속물근 훈련 기법: 
예: 평가하는 동안 model.eval() 대신 model.train()을 호출합니다.
- 잘못된 하이퍼파라미터 선택: 
동일한 구현에서 하이퍼파라미터 세트는 최신 결과를 제공할 수 있지만 다른 하이퍼파라미터 세트는 결코 수렴되지 않을 수 있습니다.
- 데이터 문제: 
일치하지 않는 입력/레이블, 과도하게 사전 처리된 데이터, 잡음이 많은 데이터 등

### Start simple and gradually add more components
가장 단순한 모델로 시작한 다음 구성 요소를 천천히 추가하여 성능에 도움이 되는지 또는 방해가 되는지 확인합니다.  
예를 들어 순환 신경망(RNN)을 구축하려는 경우 RNN 셀의 한 수준으로 시작하여 여러 개를 함께 쌓거나 정규화를 더 추가합니다.  
MLM(masked language model)과 NSP(next sentence prediction loss)를 모두 사용하는 BERT 유사 모델(Devlin et al., 2018)을 사용하려는 경우 NSP 손실을 추가하기 전에 MLM 손실만 사용하는 것이 좋습니다.

### Overfit a single batch
모델을 간단하게 구현한 후 소량의 훈련 데이터를 과대적합하고 동일한 데이터에 대해 평가를 실행하여 손실이 최소화되도록 합니다.  
이미지 인식을 위한 것이라면 10개의 이미지에 과대적합하고 정확도가 100%에 도달할 수 있는지 확인하고, 기계 번역을 위한 것이라면 100문장 쌍에 과대적합하고 100에 가까운 BLEU 점수에 도달할 수 있는지 확인합니다.  
소량의 데이터를 과대적합할 수 없다면 구현에 문제가 있는 것입니다.

### Set a random seed
가중치 초기화, 드롭아웃, 데이터 셔플링 등 모델의 무작위성에 영향을 미치는 많은 요인이 있습니다.  
무작위성은 여러 실험에서 결과를 비교하기 어렵게 만듭니다.  
성능 변화가 변화로 인한 것인지 알 수 없습니다.  
모델 또는 다른 무작위 시드에서. 임의 시드를 설정하면 서로 다른 실행 간의 일관성이 보장됩니다.  
또한 오류를 재현하고 다른 사람이 결과를 재현할 수 있습니다.

## Hyperparameter tuning
서로 다른 하이퍼파라미터 세트를 사용하면 동일한 모델이 동일한 데이터 세트에서 크게 다른 성능을 제공할 수 있습니다.  
Meliset al. 2018년 논문에서 하이퍼파라미터가 잘 조정된 약한 모델 "On the State of the Art of Evaluation in Neural Language Models" 이 더 강력한 최신 모델을 능가할 수 있음을 보여주었습니다.

하이퍼파라미터 검색 알고리즘과 좋은 하이퍼파라미터 세트를 자동으로 검색하는 데 도움이 되는 도구에 대해 많은 연구가 수행되었습니다.  
임의 검색, 그리드 검색, 베이지안 최적화를 포함하여 인기 있는 하이퍼파라미터 튜닝 방법 중 일부를 확인하고 싶을 수 있습니다.  
AutoML: Methods, Systems, Challenges라는 책은 University of Freiburg의 AutoML 그룹에서 하이퍼파라미터 최적화에 대한 첫 번째 장을 할애하고 있으며 here 에서 온라인으로 무료로 읽을 수 있습니다.

각 하이퍼파라미터 세트의 성능은 검증 세트에서 평가됩니다.  
모든 하이퍼파라미터가 동일하게 생성되는 것은 아닙니다.  
모델의 성능은 하나의 하이퍼파라미터의 변화에 더 민감할 수 있으며, 서로 다른 하이퍼파라미터의 중요성에 접근하는 연구도 수행되었습니다.

## Scaling
주 메모리에 맞지 않는 데이터 세트로 모델을 훈련시키는 것은 드문 일이 아닙니다.  
이것은 특히 CT 스캔이나 게놈 서열과 같은 의료 데이터를 다룰 때 일반적입니다.  
이와 같은 상황에 처한 경우 데이터가 메모리에 맞지 않을 때 사전 처리(예: 제로 센터링, 정규화, 화이트닝), 셔플 및 일괄 처리 방법을 알아야 합니다.  
데이터의 각 샘플이 너무 크면 모델이 매우 작은 배치 크기를 처리할 수 있으므로 확률적 경사 하강법 기반 최적화가 불안정해질 수 있습니다.

매우 드문 경우로, 각 샘플이 너무 커서 단일 샘플이 메모리에 맞지 않을 수 있습니다.  
그래디언트 체크포인트와 같은 기술을 사용해야 합니다.  
계산하지만 더 적은 메모리가 필요합니다.  
Tim Salimans와 Yaroslav Bulatov가 개발한 오픈 소스 패키지 Gradient-Checkpointing을 사용할 수 있습니다.  
패키지 작성자에 따르면 "피드 포워드 모델의 경우 계산 시간이 20%만 증가하면서 GPU에 10배 이상 큰 모델을 맞출 수 있었습니다."

가장 어려운 문제는 서로 다른 기계에서 기울기를 정확하고 효과적으로 누적하는 방법입니다.  
각 기계가 자체 기울기를 생성하기 때문에 모델이 모든 기계가 실행을 완료할 때까지 대기하는 경우(이 기술을 SSGD(동기 확률적 경사 하강법)라고 함) 낙오자는 전체 모델의 속도를 저하시킵니다.

그러나 모델이 각 머신의 그래디언트를 개별적으로 사용하여 가중치를 업데이트하는 경우(ASGD(Asynchronous SGD)라고 함) 한 머신의 그래디언트로 인해 다른 머신의 그래디언트가 변경되기 전에 가중치가 변경되기 때문에 그래디언트 부실이 발생합니다.  
그래디언트 부실을 완화하는 방법은 활발한 연구 분야입니다.

둘째, 모델을 여러 시스템에 분산하면 배치 크기가 매우 커질 수 있습니다.  
기계가 크기 128의 배치를 처리하는 경우 128대의 기계가 크기 16,384의 배치를 처리합니다.  
기계에서 한 시대를 훈련하는 데 100,000단계가 걸린다면 128개 기계에서 훈련하는 데 800단계 미만이 걸립니다.  
직관적인 접근 방식은 각 단계에서 훨씬 더 많은 학습을 설명하기 위해 여러 머신에서 학습률을 조정하는 것이지만 불안정한 수렴으로 이어질 수 있으므로 학습률을 너무 크게 만들 수도 없습니다.

마지막으로 동일한 모델 설정에서 마스터 작업자는 다른 작업자보다 훨씬 더 많은 리소스를 사용합니다.  
모든 시스템을 최대한 활용하려면 시스템 간에 워크로드의 균형을 맞추는 방법을 찾아야 합니다.  
가장 쉽지만 가장 효과적인 방법은 아닌데, 마스터 작업자에 더 작은 배치 크기를 사용하고 다른 작업자에 더 큰 배치 크기를 사용하는 것입니다.

점점 인기를 얻고 있는 스케일링 접근 방식은 훈련 중에 정밀도를 줄이는 것입니다.  
전체 32비트를 사용하여 부동 소수점 숫자를 나타내는 대신 모델의 예측력을 유지하면서 각 숫자에 대해 더 적은 비트를 사용할 수 있습니다.  
Paulius Micikevicius 외의 논문 Mixed Precision Training. NVIDIA에서 전체 부동 소수점 정밀도(32비트)와 부동 소수점 정밀도 절반(16비트)을 번갈아 사용하면 모델의 메모리 공간을 절반으로 줄일 수 있어 배치 크기를 두 배로 늘릴 수 있습니다.  
정밀도가 낮으면 계산 속도도 빨라집니다.

## Serving
훈련된 모델을 사용자에게 제공하기 전에 모델이 문제 설정에 설명된 모든 제약 조건을 충족하는지 확인하기 위해 실행해야 하는 실험을 생각해야 합니다.  
사용자로부터 어떤 피드백을 받고 싶은지, 사용자가 더 나은 예측을 제안하도록 허용할지 여부, 사용자 반응에서 모델이 잘 작동하는지 여부를 연기하는 방법을 생각해야 합니다.
