{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# One-Hot Encoding\n",
        "\n",
        "원-핫 인코딩은 선택해야 하는 선택지의 개수만큼의 차원을 가지면서, 각 선택지의 인덱스에 해당하는 원소에는 1, 나머지 원소는 0의 값을 가지도록 하는 표현 방법입니다.\n",
        "\n",
        "다중 클래스 분류 문제가 각 클래스 간의 관계가 균등하다는 점에서 원-핫 벡터는 이러한 점을 표현할 수 있는 적절한 표현 방법\n",
        "\n",
        "만약 클래스 표기를 1,2,3,4 식으로 한다면 수의 크기에 따라 가중치가 부여될 수 있음. ex) loss function을 통한 계산"
      ],
      "metadata": {
        "id": "nyz1x0_-ACG8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Softmax Regression's cost function"
      ],
      "metadata": {
        "id": "YqEmr3c3FOjh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "1v4N5xXZ_89x"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "z = torch.FloatTensor([1, 2, 3])"
      ],
      "metadata": {
        "id": "R95q7FOwFHgu"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hypothesis = F.softmax(z, dim=0)"
      ],
      "metadata": {
        "id": "lMiQVEGAFN-E"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(hypothesis)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nc5fuWHFFZrN",
        "outputId": "61600bbe-ca87-427c-ffd1-d528ae296fa8"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0.0900, 0.2447, 0.6652])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "hypothesis.sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_mlBtxLiFbw7",
        "outputId": "acab20a0-f5d9-46dc-9638-061c6a85a11b"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(1.)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# random matrix\n",
        "z = torch.rand(3,5, requires_grad=True)"
      ],
      "metadata": {
        "id": "zaw8TCO7FdzG"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hypothesis = F.softmax(z, dim=1)"
      ],
      "metadata": {
        "id": "-N_S5sOnFpKM"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "z"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z8rfjXVkFq1c",
        "outputId": "8398761c-8904-4f25-a237-4130a478f35b"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.3029, 0.4437, 0.3436, 0.8640, 0.5296],\n",
              "        [0.3061, 0.6031, 0.9009, 0.9213, 0.8244],\n",
              "        [0.2185, 0.3983, 0.9097, 0.1714, 0.0017]], requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(hypothesis)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bxXxgA3bFvr-",
        "outputId": "ad53308b-8177-40ac-b71e-b29de31f6e24"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.1613, 0.1857, 0.1680, 0.2827, 0.2023],\n",
            "        [0.1301, 0.1751, 0.2358, 0.2406, 0.2184],\n",
            "        [0.1680, 0.2011, 0.3354, 0.1603, 0.1353]], grad_fn=<SoftmaxBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y = torch.randint(5,(3,)).long()\n",
        "print(y)\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FjICJ3urFxZc",
        "outputId": "2923bc75-7ac8-4a8c-a5e0-df1d0935bf3d"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([2, 3, 4])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 모든 원소가 0의 값을 가진 3 × 5 텐서 생성\n",
        "y_one_hot = torch.zeros_like(hypothesis)\n",
        "y_one_hot.scatter_(1, y.unsqueeze(1), 1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "81Sv4MfqF0Gx",
        "outputId": "8247a910-ecea-4b75-8553-b6698b45125b"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0., 0., 1., 0., 0.],\n",
              "        [0., 0., 0., 1., 0.],\n",
              "        [0., 0., 0., 0., 1.]])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "$cost(W) = \\frac{1}{n} \\sum_{i=1}^{n} \\sum_{j=1}^{k}y_{j}^{(i)}\\ × (-log(p_{j}^{(i)}))$"
      ],
      "metadata": {
        "id": "7-Bmo9CqGCba"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cost = (y_one_hot * -torch.log(hypothesis)).sum(dim=1).mean()"
      ],
      "metadata": {
        "id": "Cm3f4MjnF4J6"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(cost)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IRdPYBLBGGIf",
        "outputId": "095f55a6-b553-407e-821b-e03302f249b5"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(1.7363, grad_fn=<MeanBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "F.softmax() + torch.log() = F.log_softmax()"
      ],
      "metadata": {
        "id": "_FTeG1FxHTNi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Low level\n",
        "torch.log(F.softmax(z, dim=1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qpJ98mdqGHs3",
        "outputId": "7b76004b-24b3-44b6-e06f-4a11721e428d"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-1.8245, -1.6837, -1.7838, -1.2634, -1.5978],\n",
              "        [-2.0396, -1.7426, -1.4448, -1.4244, -1.5213],\n",
              "        [-1.7837, -1.6040, -1.0926, -1.8309, -2.0006]], grad_fn=<LogBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# High level\n",
        "F.log_softmax(z, dim=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GexO1-mrHU-o",
        "outputId": "d950c91a-ffaf-4087-874b-e19472e4324c"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-1.8245, -1.6837, -1.7838, -1.2634, -1.5978],\n",
              "        [-2.0396, -1.7426, -1.4448, -1.4244, -1.5213],\n",
              "        [-1.7837, -1.6040, -1.0926, -1.8309, -2.0006]],\n",
              "       grad_fn=<LogSoftmaxBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "F.log_softmax() + F.nll_loss() = F.cross_entropy()"
      ],
      "metadata": {
        "id": "7-OefSQ6HffH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 첫번째 수식\n",
        "(y_one_hot * -torch.log(F.softmax(z, dim=1))).sum(dim=1).mean()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6CFJ4wVIHbHz",
        "outputId": "c5a1a394-75e0-454b-f30a-0914211fc293"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(1.7363, grad_fn=<MeanBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 두번째 수식\n",
        "(y_one_hot * - F.log_softmax(z, dim=1)).sum(dim=1).mean()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WYB2GtqcHk3W",
        "outputId": "f318fc15-8633-4592-8db8-224e6a1fd5a6"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(1.7363, grad_fn=<MeanBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 세번째 수식\n",
        "F.nll_loss(F.log_softmax(z, dim=1), y) # nll이란 Negative Log Likelihood의 약자"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "edkvnXeQHobI",
        "outputId": "7f258b89-c3d8-4aa7-ca5f-40a482abeaa9"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(1.7363, grad_fn=<NllLossBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 네번째 수식\n",
        "F.cross_entropy(z, y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IVgfZsamHtY7",
        "outputId": "438fe4ce-1a4b-42ba-c830-47d2f098d84e"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(1.7363, grad_fn=<NllLossBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "F.cross_entropy는 비용 함수에 소프트맥스 함수까지 포함하고 있음을 기억하고 있어야 구현 시 혼동하지 않습니다."
      ],
      "metadata": {
        "id": "UGhqWFebH30E"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Softmax Regression Implementation"
      ],
      "metadata": {
        "id": "UcmTDn4sH63-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "\n",
        "torch.manual_seed(1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ixUzny4EHzyc",
        "outputId": "05c33756-f03a-4d84-8b20-bdcd5e4870d4"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7968f2398990>"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train = [[1, 2, 1, 1],\n",
        "           [2, 1, 3, 2],\n",
        "           [3, 1, 3, 4],\n",
        "           [4, 1, 5, 5],\n",
        "           [1, 7, 5, 5],\n",
        "           [1, 2, 5, 6],\n",
        "           [1, 6, 6, 6],\n",
        "           [1, 7, 7, 7]]\n",
        "y_train = [2, 2, 2, 1, 1, 1, 0, 0]\n",
        "x_train = torch.FloatTensor(x_train)\n",
        "y_train = torch.LongTensor(y_train)"
      ],
      "metadata": {
        "id": "pACO0T55H_S_"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_one_hot = torch.zeros(8, 3)\n",
        "y_one_hot.scatter_(1, y_train.unsqueeze(1), 1)\n",
        "print(y_one_hot.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dLmEl06VIDcz",
        "outputId": "f7c8d2d7-d4a0-44ab-e731-cc8f9f8d56d8"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([8, 3])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_one_hot #y_train에서 원-핫 인코딩을 한 결과이어야 합니다. 클래스의 개수는 3개이므로 y_train에 원-핫 인코딩한 결과는 8 × 3의 개수를 가져야 합니다."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5RNZcRUbIOwf",
        "outputId": "c8e7af69-b974-44d5-8079-7da20800c158"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0., 0., 1.],\n",
              "        [0., 0., 1.],\n",
              "        [0., 0., 1.],\n",
              "        [0., 1., 0.],\n",
              "        [0., 1., 0.],\n",
              "        [0., 1., 0.],\n",
              "        [1., 0., 0.],\n",
              "        [1., 0., 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "W = torch.zeros((4, 3), requires_grad=True)\n",
        "b = torch.zeros(1, requires_grad=True)\n",
        "# optimizer 설정\n",
        "optimizer = optim.SGD([W, b], lr=0.1)"
      ],
      "metadata": {
        "id": "tqzM55jwIQmJ"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nb_epochs = 5000\n",
        "for epoch in range(nb_epochs + 1):\n",
        "\n",
        "    # 가설\n",
        "    hypothesis = F.softmax(x_train.matmul(W) + b, dim=1)\n",
        "\n",
        "    # 비용 함수\n",
        "    cost = (y_one_hot * -torch.log(hypothesis)).sum(dim=1).mean()\n",
        "\n",
        "    # cost로 H(x) 개선\n",
        "    optimizer.zero_grad()\n",
        "    cost.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    # 100번마다 로그 출력\n",
        "    if epoch % 100 == 0:\n",
        "        print('Epoch {:4d}/{} Cost: {:.6f}'.format(\n",
        "            epoch, nb_epochs, cost.item()\n",
        "        ))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "anZMoZiOIdX8",
        "outputId": "cb8b4022-2e78-4fb5-abf3-dd3610489d28"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch    0/5000 Cost: 0.114068\n",
            "Epoch  100/5000 Cost: 0.112499\n",
            "Epoch  200/5000 Cost: 0.110970\n",
            "Epoch  300/5000 Cost: 0.109480\n",
            "Epoch  400/5000 Cost: 0.108028\n",
            "Epoch  500/5000 Cost: 0.106612\n",
            "Epoch  600/5000 Cost: 0.105230\n",
            "Epoch  700/5000 Cost: 0.103883\n",
            "Epoch  800/5000 Cost: 0.102568\n",
            "Epoch  900/5000 Cost: 0.101284\n",
            "Epoch 1000/5000 Cost: 0.100031\n",
            "Epoch 1100/5000 Cost: 0.098806\n",
            "Epoch 1200/5000 Cost: 0.097611\n",
            "Epoch 1300/5000 Cost: 0.096442\n",
            "Epoch 1400/5000 Cost: 0.095300\n",
            "Epoch 1500/5000 Cost: 0.094183\n",
            "Epoch 1600/5000 Cost: 0.093092\n",
            "Epoch 1700/5000 Cost: 0.092024\n",
            "Epoch 1800/5000 Cost: 0.090979\n",
            "Epoch 1900/5000 Cost: 0.089957\n",
            "Epoch 2000/5000 Cost: 0.088957\n",
            "Epoch 2100/5000 Cost: 0.087978\n",
            "Epoch 2200/5000 Cost: 0.087019\n",
            "Epoch 2300/5000 Cost: 0.086080\n",
            "Epoch 2400/5000 Cost: 0.085161\n",
            "Epoch 2500/5000 Cost: 0.084260\n",
            "Epoch 2600/5000 Cost: 0.083377\n",
            "Epoch 2700/5000 Cost: 0.082512\n",
            "Epoch 2800/5000 Cost: 0.081664\n",
            "Epoch 2900/5000 Cost: 0.080833\n",
            "Epoch 3000/5000 Cost: 0.080018\n",
            "Epoch 3100/5000 Cost: 0.079218\n",
            "Epoch 3200/5000 Cost: 0.078434\n",
            "Epoch 3300/5000 Cost: 0.077664\n",
            "Epoch 3400/5000 Cost: 0.076909\n",
            "Epoch 3500/5000 Cost: 0.076168\n",
            "Epoch 3600/5000 Cost: 0.075441\n",
            "Epoch 3700/5000 Cost: 0.074727\n",
            "Epoch 3800/5000 Cost: 0.074026\n",
            "Epoch 3900/5000 Cost: 0.073337\n",
            "Epoch 4000/5000 Cost: 0.072661\n",
            "Epoch 4100/5000 Cost: 0.071997\n",
            "Epoch 4200/5000 Cost: 0.071344\n",
            "Epoch 4300/5000 Cost: 0.070703\n",
            "Epoch 4400/5000 Cost: 0.070073\n",
            "Epoch 4500/5000 Cost: 0.069453\n",
            "Epoch 4600/5000 Cost: 0.068844\n",
            "Epoch 4700/5000 Cost: 0.068246\n",
            "Epoch 4800/5000 Cost: 0.067657\n",
            "Epoch 4900/5000 Cost: 0.067078\n",
            "Epoch 5000/5000 Cost: 0.066509\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 다시 구현"
      ],
      "metadata": {
        "id": "8zN-foRPI0I8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 초기화\n",
        "W = torch.zeros((4, 3), requires_grad=True)\n",
        "b = torch.zeros((1, 3), requires_grad=True)\n",
        "# optimizer 설정\n",
        "optimizer = optim.SGD([W, b], lr=0.1)\n",
        "\n",
        "nb_epochs = 5000\n",
        "for epoch in range(nb_epochs + 1):\n",
        "\n",
        "    # Cost 계산\n",
        "    z = x_train.matmul(W) + b\n",
        "    cost = F.cross_entropy(z, y_train)\n",
        "\n",
        "    # cost로 H(x) 개선\n",
        "    optimizer.zero_grad()\n",
        "    cost.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    # 100번마다 로그 출력\n",
        "    if epoch % 100 == 0:\n",
        "        print('Epoch {:4d}/{} Cost: {:.6f}'.format(\n",
        "            epoch, nb_epochs, cost.item()\n",
        "        ))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iAe-vJGJIhUK",
        "outputId": "37186229-8675-4629-80c0-73af9d123342"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch    0/5000 Cost: 1.098612\n",
            "Epoch  100/5000 Cost: 0.704199\n",
            "Epoch  200/5000 Cost: 0.623000\n",
            "Epoch  300/5000 Cost: 0.565717\n",
            "Epoch  400/5000 Cost: 0.515291\n",
            "Epoch  500/5000 Cost: 0.467662\n",
            "Epoch  600/5000 Cost: 0.421278\n",
            "Epoch  700/5000 Cost: 0.375402\n",
            "Epoch  800/5000 Cost: 0.329766\n",
            "Epoch  900/5000 Cost: 0.285073\n",
            "Epoch 1000/5000 Cost: 0.248155\n",
            "Epoch 1100/5000 Cost: 0.232676\n",
            "Epoch 1200/5000 Cost: 0.221399\n",
            "Epoch 1300/5000 Cost: 0.211129\n",
            "Epoch 1400/5000 Cost: 0.201736\n",
            "Epoch 1500/5000 Cost: 0.193113\n",
            "Epoch 1600/5000 Cost: 0.185170\n",
            "Epoch 1700/5000 Cost: 0.177829\n",
            "Epoch 1800/5000 Cost: 0.171027\n",
            "Epoch 1900/5000 Cost: 0.164707\n",
            "Epoch 2000/5000 Cost: 0.158821\n",
            "Epoch 2100/5000 Cost: 0.153327\n",
            "Epoch 2200/5000 Cost: 0.148186\n",
            "Epoch 2300/5000 Cost: 0.143368\n",
            "Epoch 2400/5000 Cost: 0.138843\n",
            "Epoch 2500/5000 Cost: 0.134586\n",
            "Epoch 2600/5000 Cost: 0.130574\n",
            "Epoch 2700/5000 Cost: 0.126786\n",
            "Epoch 2800/5000 Cost: 0.123206\n",
            "Epoch 2900/5000 Cost: 0.119817\n",
            "Epoch 3000/5000 Cost: 0.116604\n",
            "Epoch 3100/5000 Cost: 0.113554\n",
            "Epoch 3200/5000 Cost: 0.110655\n",
            "Epoch 3300/5000 Cost: 0.107897\n",
            "Epoch 3400/5000 Cost: 0.105269\n",
            "Epoch 3500/5000 Cost: 0.102763\n",
            "Epoch 3600/5000 Cost: 0.100370\n",
            "Epoch 3700/5000 Cost: 0.098084\n",
            "Epoch 3800/5000 Cost: 0.095897\n",
            "Epoch 3900/5000 Cost: 0.093803\n",
            "Epoch 4000/5000 Cost: 0.091796\n",
            "Epoch 4100/5000 Cost: 0.089872\n",
            "Epoch 4200/5000 Cost: 0.088025\n",
            "Epoch 4300/5000 Cost: 0.086251\n",
            "Epoch 4400/5000 Cost: 0.084545\n",
            "Epoch 4500/5000 Cost: 0.082904\n",
            "Epoch 4600/5000 Cost: 0.081324\n",
            "Epoch 4700/5000 Cost: 0.079802\n",
            "Epoch 4800/5000 Cost: 0.078335\n",
            "Epoch 4900/5000 Cost: 0.076919\n",
            "Epoch 5000/5000 Cost: 0.075553\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Softmax Linear Regression to nn.Module"
      ],
      "metadata": {
        "id": "mqg7_pl8JPF2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델을 선언 및 초기화. 4개의 특성을 가지고 3개의 클래스로 분류. input_dim=4, output_dim=3.\n",
        "model = nn.Linear(4, 3)\n",
        "# optimizer 설정\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.1)\n",
        "\n",
        "nb_epochs = 5000\n",
        "for epoch in range(nb_epochs + 1):\n",
        "\n",
        "    # H(x) 계산\n",
        "    prediction = model(x_train)\n",
        "\n",
        "    # cost 계산\n",
        "    cost = F.cross_entropy(prediction, y_train)\n",
        "\n",
        "    # cost로 H(x) 개선\n",
        "    optimizer.zero_grad()\n",
        "    cost.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    # 20번마다 로그 출력\n",
        "    if epoch % 100 == 0:\n",
        "        print('Epoch {:4d}/{} Cost: {:.6f}'.format(\n",
        "            epoch, nb_epochs, cost.item()\n",
        "        ))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MVismgKsI4LA",
        "outputId": "bcae9af4-0510-48fb-a50c-836d9f3e8a06"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch    0/5000 Cost: 1.616785\n",
            "Epoch  100/5000 Cost: 0.658891\n",
            "Epoch  200/5000 Cost: 0.573443\n",
            "Epoch  300/5000 Cost: 0.518151\n",
            "Epoch  400/5000 Cost: 0.473265\n",
            "Epoch  500/5000 Cost: 0.433516\n",
            "Epoch  600/5000 Cost: 0.396563\n",
            "Epoch  700/5000 Cost: 0.360914\n",
            "Epoch  800/5000 Cost: 0.325392\n",
            "Epoch  900/5000 Cost: 0.289178\n",
            "Epoch 1000/5000 Cost: 0.254148\n",
            "Epoch 1100/5000 Cost: 0.234973\n",
            "Epoch 1200/5000 Cost: 0.223493\n",
            "Epoch 1300/5000 Cost: 0.213053\n",
            "Epoch 1400/5000 Cost: 0.203509\n",
            "Epoch 1500/5000 Cost: 0.194751\n",
            "Epoch 1600/5000 Cost: 0.186687\n",
            "Epoch 1700/5000 Cost: 0.179238\n",
            "Epoch 1800/5000 Cost: 0.172338\n",
            "Epoch 1900/5000 Cost: 0.165930\n",
            "Epoch 2000/5000 Cost: 0.159963\n",
            "Epoch 2100/5000 Cost: 0.154396\n",
            "Epoch 2200/5000 Cost: 0.149189\n",
            "Epoch 2300/5000 Cost: 0.144311\n",
            "Epoch 2400/5000 Cost: 0.139730\n",
            "Epoch 2500/5000 Cost: 0.135422\n",
            "Epoch 2600/5000 Cost: 0.131363\n",
            "Epoch 2700/5000 Cost: 0.127533\n",
            "Epoch 2800/5000 Cost: 0.123913\n",
            "Epoch 2900/5000 Cost: 0.120487\n",
            "Epoch 3000/5000 Cost: 0.117240\n",
            "Epoch 3100/5000 Cost: 0.114159\n",
            "Epoch 3200/5000 Cost: 0.111231\n",
            "Epoch 3300/5000 Cost: 0.108445\n",
            "Epoch 3400/5000 Cost: 0.105792\n",
            "Epoch 3500/5000 Cost: 0.103262\n",
            "Epoch 3600/5000 Cost: 0.100847\n",
            "Epoch 3700/5000 Cost: 0.098540\n",
            "Epoch 3800/5000 Cost: 0.096334\n",
            "Epoch 3900/5000 Cost: 0.094221\n",
            "Epoch 4000/5000 Cost: 0.092198\n",
            "Epoch 4100/5000 Cost: 0.090257\n",
            "Epoch 4200/5000 Cost: 0.088395\n",
            "Epoch 4300/5000 Cost: 0.086606\n",
            "Epoch 4400/5000 Cost: 0.084887\n",
            "Epoch 4500/5000 Cost: 0.083233\n",
            "Epoch 4600/5000 Cost: 0.081641\n",
            "Epoch 4700/5000 Cost: 0.080107\n",
            "Epoch 4800/5000 Cost: 0.078629\n",
            "Epoch 4900/5000 Cost: 0.077204\n",
            "Epoch 5000/5000 Cost: 0.075828\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Softmax class"
      ],
      "metadata": {
        "id": "pkyTvuxCJkyi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SoftmaxClassifierModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.linear = nn.Linear(4, 3) # Output이 3!\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.linear(x)"
      ],
      "metadata": {
        "id": "quPcJchJJe7p"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = SoftmaxClassifierModel()\n",
        "\n",
        "\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.1)\n",
        "\n",
        "nb_epochs = 5000\n",
        "for epoch in range(nb_epochs + 1):\n",
        "\n",
        "    # H(x) 계산\n",
        "    prediction = model(x_train)\n",
        "\n",
        "    # cost 계산\n",
        "    cost = F.cross_entropy(prediction, y_train)\n",
        "\n",
        "    # cost로 H(x) 개선\n",
        "    optimizer.zero_grad()\n",
        "    cost.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    # 20번마다 로그 출력\n",
        "    if epoch % 100 == 0:\n",
        "        print('Epoch {:4d}/{} Cost: {:.6f}'.format(\n",
        "            epoch, nb_epochs, cost.item()\n",
        "        ))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i0o6lfRZJmnk",
        "outputId": "237d4f28-c033-4841-f762-02a15d96704b"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch    0/5000 Cost: 2.637636\n",
            "Epoch  100/5000 Cost: 0.647903\n",
            "Epoch  200/5000 Cost: 0.564643\n",
            "Epoch  300/5000 Cost: 0.511043\n",
            "Epoch  400/5000 Cost: 0.467249\n",
            "Epoch  500/5000 Cost: 0.428280\n",
            "Epoch  600/5000 Cost: 0.391924\n",
            "Epoch  700/5000 Cost: 0.356742\n",
            "Epoch  800/5000 Cost: 0.321577\n",
            "Epoch  900/5000 Cost: 0.285617\n",
            "Epoch 1000/5000 Cost: 0.250818\n",
            "Epoch 1100/5000 Cost: 0.232102\n",
            "Epoch 1200/5000 Cost: 0.220866\n",
            "Epoch 1300/5000 Cost: 0.210637\n",
            "Epoch 1400/5000 Cost: 0.201279\n",
            "Epoch 1500/5000 Cost: 0.192685\n",
            "Epoch 1600/5000 Cost: 0.184767\n",
            "Epoch 1700/5000 Cost: 0.177449\n",
            "Epoch 1800/5000 Cost: 0.170667\n",
            "Epoch 1900/5000 Cost: 0.164366\n",
            "Epoch 2000/5000 Cost: 0.158497\n",
            "Epoch 2100/5000 Cost: 0.153018\n",
            "Epoch 2200/5000 Cost: 0.147892\n",
            "Epoch 2300/5000 Cost: 0.143087\n",
            "Epoch 2400/5000 Cost: 0.138574\n",
            "Epoch 2500/5000 Cost: 0.134328\n",
            "Epoch 2600/5000 Cost: 0.130327\n",
            "Epoch 2700/5000 Cost: 0.126550\n",
            "Epoch 2800/5000 Cost: 0.122979\n",
            "Epoch 2900/5000 Cost: 0.119599\n",
            "Epoch 3000/5000 Cost: 0.116394\n",
            "Epoch 3100/5000 Cost: 0.113352\n",
            "Epoch 3200/5000 Cost: 0.110461\n",
            "Epoch 3300/5000 Cost: 0.107709\n",
            "Epoch 3400/5000 Cost: 0.105088\n",
            "Epoch 3500/5000 Cost: 0.102588\n",
            "Epoch 3600/5000 Cost: 0.100201\n",
            "Epoch 3700/5000 Cost: 0.097921\n",
            "Epoch 3800/5000 Cost: 0.095739\n",
            "Epoch 3900/5000 Cost: 0.093650\n",
            "Epoch 4000/5000 Cost: 0.091648\n",
            "Epoch 4100/5000 Cost: 0.089729\n",
            "Epoch 4200/5000 Cost: 0.087886\n",
            "Epoch 4300/5000 Cost: 0.086116\n",
            "Epoch 4400/5000 Cost: 0.084414\n",
            "Epoch 4500/5000 Cost: 0.082776\n",
            "Epoch 4600/5000 Cost: 0.081200\n",
            "Epoch 4700/5000 Cost: 0.079681\n",
            "Epoch 4800/5000 Cost: 0.078217\n",
            "Epoch 4900/5000 Cost: 0.076805\n",
            "Epoch 5000/5000 Cost: 0.075442\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Softmax Regression : MNIST classification"
      ],
      "metadata": {
        "id": "QfAp6mvHKVpE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision.datasets as dsets\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.nn as nn\n",
        "import matplotlib.pyplot as plt\n",
        "import random"
      ],
      "metadata": {
        "id": "WHTpRJxTJsH9"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "USE_CUDA = torch.cuda.is_available() # GPU를 사용가능하면 True, 아니라면 False를 리턴\n",
        "device = torch.device(\"cuda\" if USE_CUDA else \"cpu\") # GPU 사용 가능하면 사용하고 아니면 CPU 사용\n",
        "print(\"다음 기기로 학습합니다:\", device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F7H4_uliKloi",
        "outputId": "1a3c9e52-3ed4-4ea7-80d8-35a95270a8fc"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "다음 기기로 학습합니다: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "random.seed(777)\n",
        "torch.manual_seed(777)\n",
        "if device == 'cuda':\n",
        "    torch.cuda.manual_seed_all(777)"
      ],
      "metadata": {
        "id": "3_wFEq9pK0hQ"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_epochs = 50\n",
        "batch_size = 100"
      ],
      "metadata": {
        "id": "ZJacYSGfK9VZ"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# MNIST dataset\n",
        "mnist_train = dsets.MNIST(root='MNIST_data/',\n",
        "                          train=True,\n",
        "                          transform=transforms.ToTensor(),\n",
        "                          download=True)\n",
        "\n",
        "mnist_test = dsets.MNIST(root='MNIST_data/',\n",
        "                         train=False,\n",
        "                         transform=transforms.ToTensor(),\n",
        "                         download=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aK2_jhZBLFgG",
        "outputId": "47a3913a-5c60-4dc4-fc1f-c731f5881684"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to MNIST_data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9912422/9912422 [00:00<00:00, 16352340.50it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting MNIST_data/MNIST/raw/train-images-idx3-ubyte.gz to MNIST_data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to MNIST_data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28881/28881 [00:00<00:00, 498543.88it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting MNIST_data/MNIST/raw/train-labels-idx1-ubyte.gz to MNIST_data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to MNIST_data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1648877/1648877 [00:00<00:00, 4525745.59it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting MNIST_data/MNIST/raw/t10k-images-idx3-ubyte.gz to MNIST_data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to MNIST_data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4542/4542 [00:00<00:00, 3112322.95it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting MNIST_data/MNIST/raw/t10k-labels-idx1-ubyte.gz to MNIST_data/MNIST/raw\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# dataset loader\n",
        "data_loader = DataLoader(dataset=mnist_train,\n",
        "                                          batch_size=batch_size, # 배치 크기는 100\n",
        "                                          shuffle=True,\n",
        "                                          drop_last=True)"
      ],
      "metadata": {
        "id": "PzRvpYzOLGLK"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "DataLoader에는 4개의 인자가 있습니다.\n",
        "\n",
        "첫번째 인자인 dataset은 로드할 대상을 의미하며, 두번째 인자인 batch_size는 배치 크기, shuffle은 매 에포크마다 미니 배치를 셔플할 것인지의 여부, drop_last는 마지막 배치를 버릴 것인지를 의미합니다."
      ],
      "metadata": {
        "id": "oBFEQ2cULNWc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "drop_last를 하는 이유를 이해하기 위해서 1,000개의 데이터가 있다고 했을 때, 배치 크기가 128이라고 해봅시다.\n",
        "\n",
        "1,000을 128로 나누면 총 7개가 나오고 나머지로 104개가 남습니다.\n",
        "\n",
        "이때 104개를 마지막 배치로 한다고 하였을 때 128개를 충족하지 못하였으므로 104개를 그냥 버릴 수도 있습니다.\n",
        "\n",
        "이때 마지막 배치를 버리려면 drop_last=True를 해주면 됩니다.\n",
        "\n",
        "이는 다른 미니 배치보다 개수가 적은 마지막 배치를 경사 하강법에 사용하여 마지막 배치가 상대적으로 과대 평가되는 현상을 막아줍니다."
      ],
      "metadata": {
        "id": "NRDy9xCKLW-o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "linear = nn.Linear(28*28, 10, bias=True).to(device) #연산을 어디서 할지 정함"
      ],
      "metadata": {
        "id": "ajjeIMn0LOxd"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 비용 함수와 옵티마이저 정의\n",
        "criterion = nn.CrossEntropyLoss().to(device) # 내부적으로 소프트맥스 함수를 포함하고 있음.\n",
        "optimizer = torch.optim.SGD(linear.parameters(), lr=0.1)"
      ],
      "metadata": {
        "id": "WHPiYNAJLieY"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(training_epochs): # 앞서 training_epochs의 값은 15로 지정함.\n",
        "    avg_cost = 0\n",
        "    total_batch = len(data_loader)\n",
        "\n",
        "    for X, Y in data_loader:\n",
        "        # 배치 크기가 100이므로 아래의 연산에서 X는 (100, 784)의 텐서가 된다.\n",
        "        X = X.view(-1, 28 * 28).to(device)\n",
        "        # 레이블은 원-핫 인코딩이 된 상태가 아니라 0 ~ 9의 정수.\n",
        "        Y = Y.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        hypothesis = linear(X)\n",
        "        cost = criterion(hypothesis, Y)\n",
        "        cost.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        avg_cost += cost / total_batch\n",
        "\n",
        "    print('Epoch:', '%04d' % (epoch + 1), 'cost =', '{:.9f}'.format(avg_cost))\n",
        "\n",
        "print('Learning finished')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8LbJXmEtLl-Z",
        "outputId": "82183b5f-96ba-4bc4-8fe3-cbda6119de78"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0001 cost = 0.535150588\n",
            "Epoch: 0002 cost = 0.359577715\n",
            "Epoch: 0003 cost = 0.331264287\n",
            "Epoch: 0004 cost = 0.316404670\n",
            "Epoch: 0005 cost = 0.307106972\n",
            "Epoch: 0006 cost = 0.300456554\n",
            "Epoch: 0007 cost = 0.294933438\n",
            "Epoch: 0008 cost = 0.290956199\n",
            "Epoch: 0009 cost = 0.287074119\n",
            "Epoch: 0010 cost = 0.284515619\n",
            "Epoch: 0011 cost = 0.281914055\n",
            "Epoch: 0012 cost = 0.279526889\n",
            "Epoch: 0013 cost = 0.277636588\n",
            "Epoch: 0014 cost = 0.275874794\n",
            "Epoch: 0015 cost = 0.274422765\n",
            "Epoch: 0016 cost = 0.272883654\n",
            "Epoch: 0017 cost = 0.271629602\n",
            "Epoch: 0018 cost = 0.270609826\n",
            "Epoch: 0019 cost = 0.269295007\n",
            "Epoch: 0020 cost = 0.268277347\n",
            "Epoch: 0021 cost = 0.267255455\n",
            "Epoch: 0022 cost = 0.266613454\n",
            "Epoch: 0023 cost = 0.265661418\n",
            "Epoch: 0024 cost = 0.264922321\n",
            "Epoch: 0025 cost = 0.263888687\n",
            "Epoch: 0026 cost = 0.263269812\n",
            "Epoch: 0027 cost = 0.262586147\n",
            "Epoch: 0028 cost = 0.261751652\n",
            "Epoch: 0029 cost = 0.261135817\n",
            "Epoch: 0030 cost = 0.260536909\n",
            "Epoch: 0031 cost = 0.260275453\n",
            "Epoch: 0032 cost = 0.259709179\n",
            "Epoch: 0033 cost = 0.258947164\n",
            "Epoch: 0034 cost = 0.258617967\n",
            "Epoch: 0035 cost = 0.258048743\n",
            "Epoch: 0036 cost = 0.257542849\n",
            "Epoch: 0037 cost = 0.257166415\n",
            "Epoch: 0038 cost = 0.256698728\n",
            "Epoch: 0039 cost = 0.256314307\n",
            "Epoch: 0040 cost = 0.255765826\n",
            "Epoch: 0041 cost = 0.255531251\n",
            "Epoch: 0042 cost = 0.254914373\n",
            "Epoch: 0043 cost = 0.254686445\n",
            "Epoch: 0044 cost = 0.254367471\n",
            "Epoch: 0045 cost = 0.254017055\n",
            "Epoch: 0046 cost = 0.253749549\n",
            "Epoch: 0047 cost = 0.253456116\n",
            "Epoch: 0048 cost = 0.252950668\n",
            "Epoch: 0049 cost = 0.252729028\n",
            "Epoch: 0050 cost = 0.252436101\n",
            "Learning finished\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "training_epochs의 값은 50로 설정되어 있으며, 모델은 총 50번의 에포크 동안 학습됩니다.\n",
        "\n",
        "avg_cost는 에포크 동안의 평균 비용을 저장하는 변수이며, total_batch는 에포크당 수행할 배치(batch) 수를 계산합니다.\n",
        "\n",
        "data_loader는 미니 배치 학습을 위해 데이터를 반복적으로 제공하는 역할을 합니다."
      ],
      "metadata": {
        "id": "D9AB0JgeLzSK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "루프 내부에서는 각 배치마다 입력 데이터 X와 레이블 Y를 받아옵니다.\n",
        "\n",
        "이때, X는 이미지 데이터로서 (100, 784) 크기의 텐서로 변환되는데, 이는 배치 크기 100에 28x28 픽셀의 이미지가 일렬로 펼쳐진 상태를 나타냅니다.\n",
        "\n",
        "이 데이터와 레이블 Y는 모델 학습을 위해 지정된 장치(device)로 전송됩니다."
      ],
      "metadata": {
        "id": "CptSMPPaMGxB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "다음으로, 옵티마이저의 기울기 정보를 초기화하고, 모델의 가설(hypothesis)을 계산합니다.\n",
        "\n",
        "linear(X)는 모델의 순전파(forward) 과정을 수행하여 예측 값을 계산합니다.\n",
        "\n",
        "그 후, 손실 함수(criterion)를 사용하여 예측 값과 실제 레이블 Y 간의 비용(cost)을 계산합니다.\n",
        "\n",
        "이 비용은 모델의 성능을 나타내며, 비용이 작을수록 모델의 예측이 실제 값에 가까워집니다.\n",
        "\n",
        "이후, cost.backward()를 호출하여 역전파(backpropagation)를 수행하고, 기울기를 계산합니다.\n",
        "\n",
        "그리고 옵티마이저의 step()을 호출하여 모델의 파라미터(가중치와 편향)를 업데이트합니다.\n",
        "\n",
        "각 배치의 비용을 avg_cost에 누적하여 에포크당 평균 비용을 계산하고, 에포크가 끝날 때마다 현재 에포크 번호와 평균 비용을 출력합니다.\n",
        "\n",
        "모든 에포크가 종료되면 \"Learning finished\" 메시지를 출력하여 학습이 완료되었음을 알립니다."
      ],
      "metadata": {
        "id": "do0J8iE9ML2J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "  x_test = mnist_test.test_data.view(-1, 28*28).float().to(device)\n",
        "  y_test = mnist_test.test_labels.to(device)\n",
        "\n",
        "  pred = linear(x_test)\n",
        "  correct_prediction = torch.argmax(pred, 1) == y_test\n",
        "  accuracy = correct_prediction.float().mean()\n",
        "  print('Accuracy:', accuracy.item())\n",
        "\n",
        "  r = random.randint(0, len(mnist_test) - 1)\n",
        "  X_single_data = mnist_test.test_data[r:r + 1].view(-1, 28 * 28).float().to(device)\n",
        "  Y_single_data = mnist_test.test_labels[r:r + 1].to(device)\n",
        "\n",
        "  print('Label: ', Y_single_data.item())\n",
        "  single_prediction = linear(X_single_data)\n",
        "  print('Prediction: ', torch.argmax(single_prediction, 1).item())\n",
        "\n",
        "  plt.imshow(mnist_test.test_data[r:r + 1].view(28, 28), cmap='Greys', interpolation='nearest')\n",
        "  plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 482
        },
        "id": "fUicnfm6LoMr",
        "outputId": "2dcec268-711f-4748-cf8e-e03c415af3b2"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.8729999661445618\n",
            "Label:  2\n",
            "Prediction:  2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaAAAAGdCAYAAABU0qcqAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAcF0lEQVR4nO3de2zV9f3H8dcp0CNqe7DW9vSMlhW8sAl0G4OuUZmOhrZLCCDb8LIFmMHJWiNWh+miILqsDhJnNEy3ZMLMRMVMIJrJgsWWOAsLKBKy2VBS1xJ6yiT2nFKkEPr5/UE4P46Uy/dwTt9teT6Sk8A5593z3ncnffrtOZz6nHNOAAD0szTrBQAAlycCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATAy3XuCrent7dfDgQWVkZMjn81mvAwDwyDmnrq4uhUIhpaWd+zxnwAXo4MGDys/Pt14DAHCJ2traNHr06HPePuAClJGRIenU4pmZmcbbAAC8ikajys/Pj30/P5eUBWj16tVatWqVwuGwioqK9MILL2jq1KkXnDv9Y7fMzEwCBACD2IVeRknJmxDeeOMNVVdXa/ny5froo49UVFSksrIyHTp0KBUPBwAYhFISoGeffVaLFi3SwoUL9c1vflMvvfSSrrzySr388supeDgAwCCU9AAdP35cu3btUmlp6f8/SFqaSktL1djYeNb9e3p6FI1G4y4AgKEv6QH6/PPPdfLkSeXm5sZdn5ubq3A4fNb9a2trFQgEYhfeAQcAlwfzf4haU1OjSCQSu7S1tVmvBADoB0l/F1x2draGDRumjo6OuOs7OjoUDAbPur/f75ff70/2GgCAAS7pZ0Dp6emaPHmy6urqYtf19vaqrq5OJSUlyX44AMAglZJ/B1RdXa358+fru9/9rqZOnarnnntO3d3dWrhwYSoeDgAwCKUkQPPmzdP//vc/LVu2TOFwWN/61re0efPms96YAAC4fPmcc856iTNFo1EFAgFFIhE+CQEABqGL/T5u/i44AMDliQABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwMt14AGEhOnjzpecY553nm3Xff9Tzz2WefeZ7pT8uWLfM809nZ6XnmmWee8TxTXV3teUaSRowYkdAcLg5nQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACZ9L5JMUUygajSoQCCgSiSgzM9N6HQwAvb29nmf+8Y9/JPRYDz30kOeZ5ubmhB4L/ae0tDShuc2bN3ueSUvjv+sv9vs4RwoAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMDHcegHgQsLhsOeZ2bNnJ/RYJ06cSGhuoLrmmmsSmhs+3Pu3hhUrVnieefrppz3PtLe3e5557733PM9I0ieffOJ55tvf/nZCj3U54gwIAGCCAAEATCQ9QE8++aR8Pl/cZfz48cl+GADAIJeS14BuvvnmuJ+5JvLzZADA0JaSMgwfPlzBYDAVXxoAMESk5DWgffv2KRQKaezYsbr33nvV2tp6zvv29PQoGo3GXQAAQ1/SA1RcXKy1a9dq8+bNevHFF9XS0qLbbrtNXV1dfd6/trZWgUAgdsnPz0/2SgCAASjpAaqoqNCPf/xjTZo0SWVlZfr73/+uzs5OrV+/vs/719TUKBKJxC5tbW3JXgkAMACl/N0Bo0aN0o033qjm5uY+b/f7/fL7/aleAwAwwKT83wEdOXJE+/fvV15eXqofCgAwiCQ9QI8++qgaGhr02Wef6cMPP9ScOXM0bNgw3X333cl+KADAIJb0H8EdOHBAd999tw4fPqzrrrtOt956q7Zv367rrrsu2Q8FABjEkh6g119/PdlfEpe5UCjkeWbx4sUJPdaGDRsSmusPS5cu9Tzz85//PKHHGjlyZEJzXiXyo/k5c+akYJO+paen99tjXY74LDgAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwETKfyEdYOG5557r1zlIPT09nmcG+ocXX3311dYrDGmcAQEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEn4YNICnef/99zzNvvPFGCjY5289+9rOE5goKCpK8Cc7EGRAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIPIwWQFAcPHrRe4ZwmTZqU0JzP50vyJjgTZ0AAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAk+jBTAWcLhsOeZJ598MvmLJMn06dOtV0AfOAMCAJggQAAAE54DtG3bNs2cOVOhUEg+n08bN26Mu905p2XLlikvL08jR45UaWmp9u3bl6x9AQBDhOcAdXd3q6ioSKtXr+7z9pUrV+r555/XSy+9pB07duiqq65SWVmZjh07dsnLAgCGDs9vQqioqFBFRUWftznn9Nxzz+nxxx/XrFmzJEmvvPKKcnNztXHjRt11112Xti0AYMhI6mtALS0tCofDKi0tjV0XCARUXFysxsbGPmd6enoUjUbjLgCAoS+pATr91s3c3Ny463Nzc8/5ts7a2loFAoHYJT8/P5krAQAGKPN3wdXU1CgSicQubW1t1isBAPpBUgMUDAYlSR0dHXHXd3R0xG77Kr/fr8zMzLgLAGDoS2qACgsLFQwGVVdXF7suGo1qx44dKikpSeZDAQAGOc/vgjty5Iiam5tjf29padHu3buVlZWlgoICLVmyRL/5zW90ww03qLCwUE888YRCoZBmz56dzL0BAIOc5wDt3LlTd9xxR+zv1dXVkqT58+dr7dq1Wrp0qbq7u3X//fers7NTt956qzZv3qwrrrgieVsDAAY9n3POWS9xpmg0qkAgoEgkwutBwBm+/PJLzzPbtm1L6LF+9KMfeZ7p7u5O6LH6w6pVqxKae+SRR5K8yeXhYr+Pm78LDgBweSJAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJz7+OAYCNAwcOeJ5J5FOtpYH9yda//e1vPc8sXLgwBZvgUnEGBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCY4MNIASTFmDFjPM9s3LjR88yECRM8zwwbNszzDFKPMyAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQfRgoMEo2NjZ5nuru7U7BJ3+bNm+d5pqioKAWbYLDgDAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMMGHkSJhra2tnmfC4XAKNhl8Vq9e7Xnmb3/7Wwo26VthYaHnmYceeigFm2Ao4wwIAGCCAAEATHgO0LZt2zRz5kyFQiH5fD5t3Lgx7vYFCxbI5/PFXcrLy5O1LwBgiPAcoO7ubhUVFZ33Z9jl5eVqb2+PXV577bVLWhIAMPR4fhNCRUWFKioqznsfv9+vYDCY8FIAgKEvJa8B1dfXKycnRzfddJMWL16sw4cPn/O+PT09ikajcRcAwNCX9ACVl5frlVdeUV1dnX73u9+poaFBFRUVOnnyZJ/3r62tVSAQiF3y8/OTvRIAYABK+r8Duuuuu2J/njhxoiZNmqRx48apvr5e06dPP+v+NTU1qq6ujv09Go0SIQC4DKT8bdhjx45Vdna2mpub+7zd7/crMzMz7gIAGPpSHqADBw7o8OHDysvLS/VDAQAGEc8/gjty5Ejc2UxLS4t2796trKwsZWVlacWKFZo7d66CwaD279+vpUuX6vrrr1dZWVlSFwcADG6eA7Rz507dcccdsb+ffv1m/vz5evHFF7Vnzx795S9/UWdnp0KhkGbMmKGnn35afr8/eVsDAAY9n3POWS9xpmg0qkAgoEgkMqReDzrXuwDPp7Gx0fPMli1bPM90dnZ6npGkv/71r55nvvjii4QeC/3rXK/Zns/YsWNTsAkGo4v9Ps5nwQEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMBE0n8l9+WgtbXV80x5ebnnmU8//dTzDJAMiTxfn3nmGc8zM2fO9DwzYsQIzzMYmDgDAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBM+JxzznqJM0WjUQUCAUUiEWVmZlqv06drrrnG80wkEvE8U1ZW5nnm1ltv9TxTVVXleSZRBw4c8DwzceLEFGxiq7Cw0PPMlClTPM+sX7/e80x/WrhwoeeZP/7xj55nhg/nc5f708V+H+cMCABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwwSf0JaCzs9PzTEVFheeZZ5991vPM+PHjPc8k6sMPP/Q8c+edd6Zgk+QpKCjwPDN//nzPM4sXL/Y8k52d7Xnmtttu8zwjScuWLfM888UXX3ieWbNmjeeZzZs3e56pr6/3PCNJN9xwQ0JzuDicAQEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJnzOOWe9xJmi0agCgYAikYgyMzOt1+mTz+fzPHPVVVd5nvnJT37ieebtt9/2PJOoI0eOeJ7p6elJwSZnW7hwYUJzTz/9tOeZUCiU0GMNZPv27fM888QTT3ieWb9+veeZRIwcOTKhuU8++cTzzPXXX5/QYw0lF/t9nDMgAIAJAgQAMOEpQLW1tZoyZYoyMjKUk5Oj2bNnq6mpKe4+x44dU2Vlpa699lpdffXVmjt3rjo6OpK6NABg8PMUoIaGBlVWVmr79u3asmWLTpw4oRkzZqi7uzt2n4cfflhvv/223nzzTTU0NOjgwYMD/peQAQD6n6ffiPrV30S4du1a5eTkaNeuXZo2bZoikYj+/Oc/a926dfrBD34g6dRvPPzGN76h7du363vf+17yNgcADGqX9BpQJBKRJGVlZUmSdu3apRMnTqi0tDR2n/Hjx6ugoECNjY19fo2enh5Fo9G4CwBg6Es4QL29vVqyZIluueUWTZgwQZIUDoeVnp6uUaNGxd03NzdX4XC4z69TW1urQCAQu+Tn5ye6EgBgEEk4QJWVldq7d69ef/31S1qgpqZGkUgkdmlra7ukrwcAGBw8vQZ0WlVVld555x1t27ZNo0ePjl0fDAZ1/PhxdXZ2xp0FdXR0KBgM9vm1/H6//H5/ImsAAAYxT2dAzjlVVVVpw4YN2rp1qwoLC+Nunzx5skaMGKG6urrYdU1NTWptbVVJSUlyNgYADAmezoAqKyu1bt06bdq0SRkZGbHXdQKBgEaOHKlAIKD77rtP1dXVysrKUmZmph588EGVlJTwDjgAQBxPAXrxxRclSbfffnvc9WvWrNGCBQskSb///e+VlpamuXPnqqenR2VlZfrDH/6QlGUBAEMHH0aagEQ+jDSRmaFo6dKlnmeeeuopzzPDhyf08qbS0vh0qkSdPHnS88wvfvELzzMvv/yy55lEPf/8855nqqqqUrDJ4MKHkQIABjQCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYSOwjgy9ziXxC7lD8NOxZs2Z5njnzN+herKF47IaiYcOGeZ7505/+5Hlm06ZNnmcOHz7seQapxxkQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGDC55xz1kucKRqNKhAIKBKJKDMz03odAIBHF/t9nDMgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwISnANXW1mrKlCnKyMhQTk6OZs+eraamprj73H777fL5fHGXBx54IKlLAwAGP08BamhoUGVlpbZv364tW7boxIkTmjFjhrq7u+Put2jRIrW3t8cuK1euTOrSAIDBb7iXO2/evDnu72vXrlVOTo527dqladOmxa6/8sorFQwGk7MhAGBIuqTXgCKRiCQpKysr7vpXX31V2dnZmjBhgmpqanT06NFzfo2enh5Fo9G4CwBg6PN0BnSm3t5eLVmyRLfccosmTJgQu/6ee+7RmDFjFAqFtGfPHj322GNqamrSW2+91efXqa2t1YoVKxJdAwAwSPmccy6RwcWLF+vdd9/VBx98oNGjR5/zflu3btX06dPV3NyscePGnXV7T0+Penp6Yn+PRqPKz89XJBJRZmZmIqsBAAxFo1EFAoELfh9P6AyoqqpK77zzjrZt23be+EhScXGxJJ0zQH6/X36/P5E1AACDmKcAOef04IMPasOGDaqvr1dhYeEFZ3bv3i1JysvLS2hBAMDQ5ClAlZWVWrdunTZt2qSMjAyFw2FJUiAQ0MiRI7V//36tW7dOP/zhD3Xttddqz549evjhhzVt2jRNmjQpJf8DAACDk6fXgHw+X5/Xr1mzRgsWLFBbW5t++tOfau/everu7lZ+fr7mzJmjxx9//KJfz7nYnx0CAAamlLwGdKFW5efnq6GhwcuXBABcpvgsOACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACAieHWC3yVc06SFI1GjTcBACTi9Pfv09/Pz2XABairq0uSlJ+fb7wJAOBSdHV1KRAInPN2n7tQovpZb2+vDh48qIyMDPl8vrjbotGo8vPz1dbWpszMTKMN7XEcTuE4nMJxOIXjcMpAOA7OOXV1dSkUCikt7dyv9Ay4M6C0tDSNHj36vPfJzMy8rJ9gp3EcTuE4nMJxOIXjcIr1cTjfmc9pvAkBAGCCAAEATAyqAPn9fi1fvlx+v996FVMch1M4DqdwHE7hOJwymI7DgHsTAgDg8jCozoAAAEMHAQIAmCBAAAATBAgAYGLQBGj16tX6+te/riuuuELFxcX617/+Zb1Sv3vyySfl8/niLuPHj7deK+W2bdummTNnKhQKyefzaePGjXG3O+e0bNky5eXlaeTIkSotLdW+fftslk2hCx2HBQsWnPX8KC8vt1k2RWprazVlyhRlZGQoJydHs2fPVlNTU9x9jh07psrKSl177bW6+uqrNXfuXHV0dBhtnBoXcxxuv/32s54PDzzwgNHGfRsUAXrjjTdUXV2t5cuX66OPPlJRUZHKysp06NAh69X63c0336z29vbY5YMPPrBeKeW6u7tVVFSk1atX93n7ypUr9fzzz+ull17Sjh07dNVVV6msrEzHjh3r501T60LHQZLKy8vjnh+vvfZaP26Yeg0NDaqsrNT27du1ZcsWnThxQjNmzFB3d3fsPg8//LDefvttvfnmm2poaNDBgwd15513Gm6dfBdzHCRp0aJFcc+HlStXGm18Dm4QmDp1qqusrIz9/eTJky4UCrna2lrDrfrf8uXLXVFRkfUapiS5DRs2xP7e29vrgsGgW7VqVey6zs5O5/f73WuvvWawYf/46nFwzrn58+e7WbNmmexj5dChQ06Sa2hocM6d+v9+xIgR7s0334zd5z//+Y+T5BobG63WTLmvHgfnnPv+97/vHnroIbulLsKAPwM6fvy4du3apdLS0th1aWlpKi0tVWNjo+FmNvbt26dQKKSxY8fq3nvvVWtrq/VKplpaWhQOh+OeH4FAQMXFxZfl86O+vl45OTm66aabtHjxYh0+fNh6pZSKRCKSpKysLEnSrl27dOLEibjnw/jx41VQUDCknw9fPQ6nvfrqq8rOztaECRNUU1Ojo0ePWqx3TgPuw0i/6vPPP9fJkyeVm5sbd31ubq4+/fRTo61sFBcXa+3atbrpppvU3t6uFStW6LbbbtPevXuVkZFhvZ6JcDgsSX0+P07fdrkoLy/XnXfeqcLCQu3fv1+//vWvVVFRocbGRg0bNsx6vaTr7e3VkiVLdMstt2jChAmSTj0f0tPTNWrUqLj7DuXnQ1/HQZLuuecejRkzRqFQSHv27NFjjz2mpqYmvfXWW4bbxhvwAcL/q6ioiP150qRJKi4u1pgxY7R+/Xrdd999hpthILjrrrtif544caImTZqkcePGqb6+XtOnTzfcLDUqKyu1d+/ey+J10PM513G4//77Y3+eOHGi8vLyNH36dO3fv1/jxo3r7zX7NOB/BJedna1hw4ad9S6Wjo4OBYNBo60GhlGjRunGG29Uc3Oz9SpmTj8HeH6cbezYscrOzh6Sz4+qqiq98847ev/99+N+fUswGNTx48fV2dkZd/+h+nw413HoS3FxsSQNqOfDgA9Qenq6Jk+erLq6uth1vb29qqurU0lJieFm9o4cOaL9+/crLy/PehUzhYWFCgaDcc+PaDSqHTt2XPbPjwMHDujw4cND6vnhnFNVVZU2bNigrVu3qrCwMO72yZMna8SIEXHPh6amJrW2tg6p58OFjkNfdu/eLUkD6/lg/S6Ii/H66687v9/v1q5d6/7973+7+++/340aNcqFw2Hr1frVI4884urr611LS4v75z//6UpLS112drY7dOiQ9Wop1dXV5T7++GP38ccfO0nu2WefdR9//LH773//65xz7plnnnGjRo1ymzZtcnv27HGzZs1yhYWF7ssvvzTePLnOdxy6urrco48+6hobG11LS4t777333He+8x13ww03uGPHjlmvnjSLFy92gUDA1dfXu/b29tjl6NGjsfs88MADrqCgwG3dutXt3LnTlZSUuJKSEsOtk+9Cx6G5udk99dRTbufOna6lpcVt2rTJjR071k2bNs1483iDIkDOOffCCy+4goICl56e7qZOneq2b99uvVK/mzdvnsvLy3Pp6enua1/7mps3b55rbm62Xivl3n//fSfprMv8+fOdc6feiv3EE0+43Nxc5/f73fTp011TU5Pt0ilwvuNw9OhRN2PGDHfddde5ESNGuDFjxrhFixYNuf9I6+t/vyS3Zs2a2H2+/PJL98tf/tJdc8017sorr3Rz5sxx7e3tdkunwIWOQ2trq5s2bZrLyspyfr/fXX/99e5Xv/qVi0Qitot/Bb+OAQBgYsC/BgQAGJoIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABP/ByS4GA/gpAaOAAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "oi1c7IN6NHuU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}